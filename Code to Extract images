!pip install pymupdf Pillow transformers torch

import fitz  
import os
import json
import re
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration

pdf_path = 'IMO_class_1_Sample.pdf'  
output_dir = 'extracted_images'
json_output_path = 'final_output.json'
os.makedirs(output_dir, exist_ok=True)


processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

def generate_caption(image_path):
    image = Image.open(image_path).convert("RGB")
    inputs = processor(image, return_tensors="pt")
    out = model.generate(**inputs)
    return processor.decode(out[0], skip_special_tokens=True)

def generate_question(caption):
    # Basic rule-based enhancement
    if "clock" in caption.lower():
        return "What time is shown on the clock?"
    elif "money" in caption.lower():
        return "What is the total amount shown?"
    elif "number" in caption.lower():
        return "What number is shown in the image?"
    else:
        return f"Based on the image, {caption.lower()}, what is the most likely answer?"

def extract_answers_from_text(text):
    # Get all answers on the page
    return re.findall(r"Ans[\. ]*\[([A-D])\]", text)

def process_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    final_output = []

    for page_number in range(len(doc)):
        page = doc[page_number]
        text = page.get_text()
        answers = extract_answers_from_text(text)

        image_list = page.get_images(full=True)
        image_paths = []

        for img_index, img in enumerate(image_list):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]
            image_filename = f"page{page_number+1}_image{img_index+1}.{image_ext}"
            image_path = os.path.join(output_dir, image_filename)
            with open(image_path, "wb") as f:
                f.write(image_bytes)
            image_paths.append(image_path)

        # Assuming each question has 5 images (1 question + 4 options)
        group_size = 5
        for q_index in range(0, len(image_paths), group_size):
            question_images = image_paths[q_index:q_index + group_size]
            if len(question_images) < 1:
                continue  # skip incomplete groups

            question_image = question_images[0]
            option_images = question_images[1:]

            caption = generate_caption(question_image)
            question = generate_question(caption)
            answer_index = q_index // group_size
            correct_answer = f"Option {answers[answer_index]}" if answer_index < len(answers) else "Option A"

            final_output.append({
                "page": page_number + 1,
                "text": text.strip(),
                "question_image": question_image,
                "option_images": option_images,
                "caption": caption,
                "question": question,
                "options": ["Option A", "Option B", "Option C", "Option D"],
                "answer": correct_answer
            })

    return final_output


data = process_pdf(pdf_path)

with open(json_output_path, 'w', encoding='utf-8') as f:
    json.dump(data, f, ensure_ascii=False, indent=4)

print("All done! Output saved to:", json_output_path)

